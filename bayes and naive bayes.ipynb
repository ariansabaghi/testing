{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "#this function is used in order to chnange every number's type in a list from str to int\n",
    "def maybe_float(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except (ValueError, TypeError):\n",
    "        return s\n",
    "\n",
    "f = open(\"iris.data\", \"r\")\n",
    "data = f.read().split(\"\\n\")\n",
    "data = data[:-2]\n",
    "data = [x.split(\",\") for x in data]\n",
    "int_data = []\n",
    "for element in data:\n",
    "    int_data.append([maybe_float(x) for x in element])\n",
    "random.shuffle(int_data)\n",
    "training_data = int_data[:int(0.7*len(data))]\n",
    "test_data = int_data[int(0.7*len(data)):]\n",
    "\n",
    "\n",
    "headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "training_data = pd.DataFrame(training_data,columns=headers)\n",
    "\n",
    "#seprating training_data by class\n",
    "Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_normal(x, mean, variance):\n",
    "    \"\"\"pdf of the univariate normal distribution.\"\"\"\n",
    "    return ((1. / np.sqrt(2 * np.pi * variance)) * \n",
    "            np.exp(-(x - mean)**2 / (2 * variance)))\n",
    "\n",
    "\n",
    "def multivariate_normal(x, d, mean, covariance):\n",
    "    \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
    "    x_m = x - mean\n",
    "    return (1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * \n",
    "            np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) / 2))\n",
    "\n",
    "def accuracy(predictions, ground_truth):\n",
    "    number_of_currect_predictions = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == ground_truth[i]:\n",
    "            number_of_currect_predictions +=1\n",
    "    return number_of_currect_predictions/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section A 70% training 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "#training parameters\n",
    "mean_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "mean_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "mean_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    " \n",
    "      \n",
    "covariance_matrix_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "covariance_matrix_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "covariance_matrix_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "\n",
    "labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "ground_truth = [x[-1] for x in test_data]\n",
    "predictions = []\n",
    "for t_data in test_data:\n",
    "    x = t_data[:-1]\n",
    "    setosa_prob = multivariate_normal(x, 4, mean_Iris_setosa, covariance_matrix_Iris_setosa)\n",
    "    versicolor_prob = multivariate_normal(x, 4, mean_Iris_versicolor, covariance_matrix_Iris_versicolor)\n",
    "    virginica_prob = multivariate_normal(x, 4, mean_Iris_virginica, covariance_matrix_Iris_virginica)\n",
    "    prob_list = [setosa_prob, versicolor_prob, virginica_prob]\n",
    "    predicted_label = prob_list.index(max(prob_list))\n",
    "    predictions.append(labels[predicted_label])\n",
    "\n",
    "accuracy_value = accuracy(predictions, ground_truth)\n",
    "print(accuracy_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B 4-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9736842105263158, 0.9736842105263158, 0.9736842105263158, 0.9444444444444444] mean: 0.9663742690058479\n"
     ]
    }
   ],
   "source": [
    "chunks = [int_data[x:x+38] for x in range(0, len(int_data), 38)]\n",
    "accuracies = []\n",
    "for chunk in chunks:\n",
    "    test_data = chunk\n",
    "    chunks_copy = chunks.copy()\n",
    "    chunks_copy.remove(test_data)\n",
    "    training_data = list(itertools.chain(*chunks_copy))\n",
    "    \n",
    "    headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "    training_data = pd.DataFrame(training_data,columns=headers)\n",
    "\n",
    "\n",
    "    #seprating training_data by class\n",
    "    Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "    Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "    Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']\n",
    "\n",
    "    #training parameters\n",
    "    mean_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "    mean_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "    mean_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "\n",
    "\n",
    "    covariance_matrix_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "    covariance_matrix_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "    covariance_matrix_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "\n",
    "    labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "    ground_truth = [x[-1] for x in test_data]\n",
    "    predictions = []\n",
    "    for t_data in test_data:\n",
    "        x = t_data[:-1]\n",
    "        setosa_prob = multivariate_normal(x, 4, mean_Iris_setosa, covariance_matrix_Iris_setosa)\n",
    "        versicolor_prob = multivariate_normal(x, 4, mean_Iris_versicolor, covariance_matrix_Iris_versicolor)\n",
    "        virginica_prob = multivariate_normal(x, 4, mean_Iris_virginica, covariance_matrix_Iris_virginica)\n",
    "        prob_list = [setosa_prob, versicolor_prob, virginica_prob]\n",
    "        predicted_label = prob_list.index(max(prob_list))\n",
    "        predictions.append(labels[predicted_label])\n",
    "\n",
    "    accuracy_value = accuracy(predictions, ground_truth)\n",
    "    accuracies.append(accuracy_value)\n",
    "    \n",
    "print(accuracies,'mean:',sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Section A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "training_data = int_data[:int(0.7*len(data))]\n",
    "test_data = int_data[int(0.7*len(data)):]\n",
    "labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "\n",
    "headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "training_data = pd.DataFrame(training_data, columns=headers)\n",
    "\n",
    "#seprating training_data by class\n",
    "Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']\n",
    "all_classes = [Iris_setosa_train, Iris_versicolor_train, Iris_virginica_train]\n",
    "\n",
    "ground_truth = [x[-1] for x in test_data]\n",
    "predictions = []\n",
    "\n",
    "# naive bayes\n",
    "for t_data in test_data:\n",
    "    x = t_data[:-1]\n",
    "    prob_list = []\n",
    "    for each_class in all_classes:\n",
    "        sepal_length_liklihood =  each_class[each_class.sepal_length == x[0]].shape[0]/len(each_class)\n",
    "        sepal_width_liklihood =  each_class[each_class.sepal_length == x[1]].shape[0]/len(each_class)\n",
    "        petal_length_liklihood =  each_class[each_class.sepal_length == x[2]].shape[0]/len(each_class)\n",
    "        petal_width_liklihood =  each_class[each_class.sepal_length == x[3]].shape[0]/len(each_class)\n",
    "        probablity = sepal_length_liklihood * sepal_width_liklihood * petal_length_liklihood * petal_width_liklihood * len(each_class)/len(int_data)\n",
    "        prob_list.append(probablity)\n",
    "    predicted_label = prob_list.index(max(prob_list))\n",
    "    predictions.append(labels[predicted_label])\n",
    "        \n",
    "print(accuracy(predictions, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with 4-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3684210526315789, 0.23684210526315788, 0.34210526315789475, 0.3888888888888889] mean: 0.3340643274853801\n"
     ]
    }
   ],
   "source": [
    "chunks = [int_data[x:x+38] for x in range(0, len(int_data), 38)]\n",
    "accuracies = []\n",
    "for chunk in chunks:\n",
    "    test_data = chunk\n",
    "    chunks_copy = chunks.copy()\n",
    "    chunks_copy.remove(test_data)\n",
    "    training_data = list(itertools.chain(*chunks_copy))\n",
    "    \n",
    "    headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "    training_data = pd.DataFrame(training_data,columns=headers)\n",
    "\n",
    "\n",
    "    #seprating training_data by class\n",
    "    Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "    Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "    Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']\n",
    "    all_classes = [Iris_setosa_train, Iris_versicolor_train, Iris_virginica_train]\n",
    "\n",
    "    ground_truth = [x[-1] for x in test_data]\n",
    "    predictions = []\n",
    "\n",
    "    # naive bayes\n",
    "    for t_data in test_data:\n",
    "        x = t_data[:-1]\n",
    "        prob_list = []\n",
    "        for each_class in all_classes:\n",
    "            sepal_length_liklihood =  each_class[each_class.sepal_length == x[0]].shape[0]/len(each_class)\n",
    "            sepal_width_liklihood =  each_class[each_class.sepal_length == x[1]].shape[0]/len(each_class)\n",
    "            petal_length_liklihood =  each_class[each_class.sepal_length == x[2]].shape[0]/len(each_class)\n",
    "            petal_width_liklihood =  each_class[each_class.sepal_length == x[3]].shape[0]/len(each_class)\n",
    "            probablity = sepal_length_liklihood * sepal_width_liklihood * petal_length_liklihood * petal_width_liklihood * len(each_class)/len(int_data)\n",
    "            prob_list.append(probablity)\n",
    "        predicted_label = prob_list.index(max(prob_list))\n",
    "        predictions.append(labels[predicted_label])\n",
    "        \n",
    "    accuracy_value = accuracy(predictions, ground_truth)\n",
    "    accuracies.append(accuracy_value)\n",
    "print(accuracies,'mean:',sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "training_data = int_data[:int(0.7*len(data))]\n",
    "test_data = int_data[int(0.7*len(data)):]\n",
    "labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "\n",
    "headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "training_data = pd.DataFrame(training_data, columns=headers)\n",
    "\n",
    "#seprating training_data by class\n",
    "Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']\n",
    "all_classes = [Iris_setosa_train, Iris_versicolor_train, Iris_virginica_train]\n",
    "\n",
    "ground_truth = [x[-1] for x in test_data]\n",
    "predictions = []\n",
    "\n",
    "# naive bayes\n",
    "for t_data in test_data:\n",
    "    x = t_data[:-1]\n",
    "    prob_list = []\n",
    "    for each_class in all_classes:\n",
    "        sepal_length_liklihood =  each_class[each_class.sepal_length == x[0]].shape[0]/len(each_class)\n",
    "        \n",
    "        if sepal_length_liklihood == 0 :\n",
    "            sepal_length_liklihood = 1/(len(each_class)+3)\n",
    "            \n",
    "        sepal_width_liklihood =  each_class[each_class.sepal_length == x[1]].shape[0]/len(each_class)\n",
    "        \n",
    "        if sepal_width_liklihood == 0 :\n",
    "            sepal_width_liklihood = 1/(len(each_class)+3)\n",
    "            \n",
    "        petal_length_liklihood =  each_class[each_class.sepal_length == x[2]].shape[0]/len(each_class)\n",
    "        \n",
    "        if petal_length_liklihood == 0 :\n",
    "            petal_length_liklihood = 1/(len(each_class)+3)\n",
    "            \n",
    "        petal_width_liklihood =  each_class[each_class.sepal_length == x[3]].shape[0]/len(each_class)\n",
    "       \n",
    "        if petal_width_liklihood == 0 :\n",
    "            petal_width_liklihood = 1/(len(each_class)+3)\n",
    "            \n",
    "        probablity = sepal_length_liklihood * sepal_width_liklihood * petal_length_liklihood * petal_width_liklihood * len(each_class)/len(int_data)\n",
    "        prob_list.append(probablity)\n",
    "    predicted_label = prob_list.index(max(prob_list))\n",
    "    predictions.append(labels[predicted_label])\n",
    "        \n",
    "print(accuracy(predictions, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with 4-fold validation with smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5263157894736842, 0.47368421052631576, 0.5263157894736842, 0.5277777777777778] mean: 0.5135233918128654\n"
     ]
    }
   ],
   "source": [
    "chunks = [int_data[x:x+38] for x in range(0, len(int_data), 38)]\n",
    "accuracies = []\n",
    "for chunk in chunks:\n",
    "    test_data = chunk\n",
    "    chunks_copy = chunks.copy()\n",
    "    chunks_copy.remove(test_data)\n",
    "    training_data = list(itertools.chain(*chunks_copy))\n",
    "    \n",
    "    headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "    training_data = pd.DataFrame(training_data,columns=headers)\n",
    "\n",
    "\n",
    "    #seprating training_data by class\n",
    "    Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "    Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "    Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']\n",
    "    all_classes = [Iris_setosa_train, Iris_versicolor_train, Iris_virginica_train]\n",
    "\n",
    "    ground_truth = [x[-1] for x in test_data]\n",
    "    predictions = []\n",
    "\n",
    "    # naive bayes\n",
    "    for t_data in test_data:\n",
    "        x = t_data[:-1]\n",
    "        prob_list = []\n",
    "        for each_class in all_classes:\n",
    "            sepal_length_liklihood =  each_class[each_class.sepal_length == x[0]].shape[0]/len(each_class)\n",
    "\n",
    "            if sepal_length_liklihood == 0 :\n",
    "                sepal_length_liklihood = 1/(len(each_class)+3)\n",
    "\n",
    "            sepal_width_liklihood =  each_class[each_class.sepal_length == x[1]].shape[0]/len(each_class)\n",
    "\n",
    "            if sepal_width_liklihood == 0 :\n",
    "                sepal_width_liklihood = 1/(len(each_class)+3)\n",
    "\n",
    "            petal_length_liklihood =  each_class[each_class.sepal_length == x[2]].shape[0]/len(each_class)\n",
    "\n",
    "            if petal_length_liklihood == 0 :\n",
    "                petal_length_liklihood = 1/(len(each_class)+3)\n",
    "\n",
    "            petal_width_liklihood =  each_class[each_class.sepal_length == x[3]].shape[0]/len(each_class)\n",
    "\n",
    "            if petal_width_liklihood == 0 :\n",
    "                petal_width_liklihood = 1/(len(each_class)+3)\n",
    "            \n",
    "            probablity = sepal_length_liklihood * sepal_width_liklihood * petal_length_liklihood * petal_width_liklihood * len(each_class)/len(int_data)\n",
    "            prob_list.append(probablity)\n",
    "        predicted_label = prob_list.index(max(prob_list))\n",
    "        predictions.append(labels[predicted_label])\n",
    "        \n",
    "    accuracy_value = accuracy(predictions, ground_truth)\n",
    "    accuracies.append(accuracy_value)\n",
    "print(accuracies,'mean:',sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "training_data = int_data[:int(0.7*len(data))]\n",
    "test_data = int_data[int(0.7*len(data)):]\n",
    "labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "\n",
    "headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "training_data = pd.DataFrame(training_data, columns=headers)\n",
    "\n",
    "#seprating training_data by class\n",
    "Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']\n",
    "\n",
    "#training parameters\n",
    "mean_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "mean_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "mean_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    " \n",
    "      \n",
    "variance_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].var().values\n",
    "variance_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].var().values\n",
    "variance_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].var().values\n",
    "\n",
    "ground_truth = [x[-1] for x in test_data]\n",
    "predictions = []\n",
    "for t_data in test_data:\n",
    "    x = t_data[:-1]\n",
    "    setosa_prob = len(Iris_setosa_train)/len(int_data)\n",
    "    versicolor_prob = len(Iris_versicolor_train)/len(int_data)\n",
    "    virginica_prob = len(Iris_virginica_train)/len(int_data)\n",
    "    for i in range(4):\n",
    "        setosa_prob *= univariate_normal(x[i], mean_Iris_setosa[i], variance_Iris_setosa[i])\n",
    "        versicolor_prob *= univariate_normal(x[i], mean_Iris_versicolor[i], variance_Iris_versicolor[i])\n",
    "        virginica_prob *= univariate_normal(x[i], mean_Iris_virginica[i], variance_Iris_virginica[i])\n",
    "        prob_list = [setosa_prob, versicolor_prob, virginica_prob]\n",
    "    predicted_label = prob_list.index(max(prob_list))\n",
    "    predictions.append(labels[predicted_label])\n",
    "    \n",
    "print(accuracy(predictions, ground_truth))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes 4-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9473684210526315, 0.9473684210526315, 0.9210526315789473, 0.9722222222222222] mean: 0.9470029239766082\n"
     ]
    }
   ],
   "source": [
    "chunks = [int_data[x:x+38] for x in range(0, len(int_data), 38)]\n",
    "accuracies = []\n",
    "for chunk in chunks:\n",
    "    test_data = chunk\n",
    "    chunks_copy = chunks.copy()\n",
    "    chunks_copy.remove(test_data)\n",
    "    training_data = list(itertools.chain(*chunks_copy))\n",
    "    \n",
    "    headers = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "    training_data = pd.DataFrame(training_data,columns=headers)\n",
    "\n",
    "\n",
    "    #seprating training_data by class\n",
    "    Iris_setosa_train = training_data.loc[training_data['class']=='Iris-setosa']\n",
    "    Iris_versicolor_train = training_data.loc[training_data['class']=='Iris-versicolor']\n",
    "    Iris_virginica_train = training_data.loc[training_data['class']=='Iris-virginica']\n",
    "\n",
    "    #training parameters\n",
    "    mean_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "    mean_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "    mean_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].mean().values\n",
    "\n",
    "\n",
    "    covariance_matrix_Iris_setosa = Iris_setosa_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "    covariance_matrix_Iris_versicolor = Iris_versicolor_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "    covariance_matrix_Iris_virginica = Iris_virginica_train[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].cov().values\n",
    "\n",
    "    labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "    ground_truth = [x[-1] for x in test_data]\n",
    "    predictions = []\n",
    "    for t_data in test_data:\n",
    "        x = t_data[:-1]\n",
    "        setosa_prob = len(Iris_setosa_train)/len(int_data)\n",
    "        versicolor_prob = len(Iris_versicolor_train)/len(int_data)\n",
    "        virginica_prob = len(Iris_virginica_train)/len(int_data)\n",
    "        for i in range(4):\n",
    "            setosa_prob *= univariate_normal(x[i], mean_Iris_setosa[i], variance_Iris_setosa[i])\n",
    "            versicolor_prob *= univariate_normal(x[i], mean_Iris_versicolor[i], variance_Iris_versicolor[i])\n",
    "            virginica_prob *= univariate_normal(x[i], mean_Iris_virginica[i], variance_Iris_virginica[i])\n",
    "            prob_list = [setosa_prob, versicolor_prob, virginica_prob]\n",
    "        predicted_label = prob_list.index(max(prob_list))\n",
    "        predictions.append(labels[predicted_label])\n",
    "\n",
    "    accuracy_value = accuracy(predictions, ground_truth)\n",
    "    accuracies.append(accuracy_value)\n",
    "    \n",
    "print(accuracies,'mean:',sum(accuracies)/len(accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
